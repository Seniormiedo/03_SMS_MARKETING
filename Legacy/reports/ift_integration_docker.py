#!/usr/bin/env python3
"""
Integraci√≥n IFT usando comandos Docker directos
Para evitar problemas de conexi√≥n Python-PostgreSQL
"""

import pandas as pd
import subprocess
import json
from pathlib import Path
import logging
from datetime import datetime
import time
import tempfile
import os

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ift_integration.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class IFTIntegratorDocker:
    """Integrador IFT usando Docker"""
    
    def __init__(self):
        self.df_ift = None
        
    def execute_sql(self, sql_command, description="SQL command"):
        """Ejecutar comando SQL via Docker"""
        try:
            cmd = [
                'docker-compose', 'exec', '-T', 'postgres',
                'psql', '-U', 'sms_user', '-d', 'sms_marketing',
                '-c', sql_command
            ]
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                cwd=os.getcwd()
            )
            
            if result.returncode == 0:
                logger.info(f"‚úÖ {description} ejecutado exitosamente")
                return result.stdout
            else:
                logger.error(f"‚ùå Error en {description}: {result.stderr}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando {description}: {e}")
            return None
    
    def execute_sql_file(self, sql_file_path, description="SQL file"):
        """Ejecutar archivo SQL via Docker"""
        try:
            cmd = [
                'docker-compose', 'exec', '-T', 'postgres',
                'psql', '-U', 'sms_user', '-d', 'sms_marketing',
                '-f', f'/tmp/{sql_file_path.name}'
            ]
            
            # Copiar archivo al contenedor
            copy_cmd = [
                'docker', 'cp', str(sql_file_path),
                f'sms_postgres:/tmp/{sql_file_path.name}'
            ]
            
            copy_result = subprocess.run(copy_cmd, capture_output=True, text=True)
            if copy_result.returncode != 0:
                logger.error(f"‚ùå Error copiando archivo: {copy_result.stderr}")
                return None
            
            # Ejecutar archivo
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"‚úÖ {description} ejecutado exitosamente")
                return result.stdout
            else:
                logger.error(f"‚ùå Error en {description}: {result.stderr}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando {description}: {e}")
            return None
    
    def test_connection(self):
        """Test de conexi√≥n"""
        logger.info("üîç Testing database connection...")
        
        result = self.execute_sql(
            "SELECT 'Connection OK' as status, COUNT(*) as contacts FROM contacts;",
            "Test de conexi√≥n"
        )
        
        if result:
            logger.info("‚úÖ Conexi√≥n a BD establecida")
            logger.info(f"üìä Resultado: {result.strip()}")
            return True
        else:
            logger.error("‚ùå Fallo conexi√≥n a BD")
            return False
    
    def load_ift_data(self):
        """Cargar y limpiar datos del IFT"""
        try:
            logger.info("üìÇ Cargando archivo Proveedores_05_08_2025.csv...")
            
            csv_path = Path("data/Proveedores_05_08_2025.csv")
            df = pd.read_csv(csv_path, encoding='utf-8')
            
            logger.info(f"üìã Archivo cargado: {len(df):,} registros")
            
            # Mapear columnas correctamente
            df_clean = pd.DataFrame({
                'numero_inicial': df['ZONA'],
                'numero_final': df[' NUMERACION_INICIAL'], 
                'cantidad_numeros': df[' NUMERACION_FINAL'],
                'tipo_servicio': df[' OCUPACION'].str.strip(),
                'operador': df[' MODALIDAD'].str.strip(),
                'fecha_asignacion': df[' RAZON_SOCIAL'].str.strip()
            })
            
            # Limpiar fechas
            df_clean['fecha_asignacion'] = pd.to_datetime(
                df_clean['fecha_asignacion'], 
                format='%d/%m/%Y', 
                errors='coerce'
            )
            
            # Validaciones
            initial_count = len(df_clean)
            
            df_clean = df_clean[
                (df_clean['numero_inicial'].notna()) &
                (df_clean['numero_final'].notna()) &
                (df_clean['numero_inicial'] < df_clean['numero_final']) &
                (df_clean['tipo_servicio'].isin(['MPP', 'CPP', 'FPP']))
            ]
            
            final_count = len(df_clean)
            removed = initial_count - final_count
            
            logger.info(f"üßπ Limpieza completada:")
            logger.info(f"   - Registros v√°lidos: {final_count:,}")
            logger.info(f"   - Registros removidos: {removed:,}")
            
            # Estad√≠sticas
            type_counts = df_clean['tipo_servicio'].value_counts()
            logger.info(f"üìä Distribuci√≥n por tipo:")
            for tipo, count in type_counts.items():
                percentage = (count / final_count) * 100
                logger.info(f"   - {tipo}: {count:,} ({percentage:.1f}%)")
            
            self.df_ift = df_clean
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando datos IFT: {e}")
            return False
    
    def create_ift_table(self):
        """Crear tabla para rangos IFT"""
        logger.info("üèóÔ∏è Creando tabla ift_rangos...")
        
        sql = """
        DROP TABLE IF EXISTS ift_rangos CASCADE;
        
        CREATE TABLE ift_rangos (
            id SERIAL PRIMARY KEY,
            numero_inicial BIGINT NOT NULL,
            numero_final BIGINT NOT NULL,
            cantidad_numeros INTEGER NOT NULL,
            tipo_servicio VARCHAR(10) NOT NULL,
            operador TEXT NOT NULL,
            fecha_asignacion DATE,
            created_at TIMESTAMP DEFAULT NOW(),
            
            CONSTRAINT ck_rango_valido CHECK (numero_final >= numero_inicial),
            CONSTRAINT ck_tipo_servicio CHECK (tipo_servicio IN ('MPP', 'CPP', 'FPP'))
        );
        
        -- √çndices optimizados
        CREATE INDEX idx_ift_rangos_inicial ON ift_rangos (numero_inicial);
        CREATE INDEX idx_ift_rangos_final ON ift_rangos (numero_final);
        CREATE INDEX idx_ift_rangos_rango ON ift_rangos (numero_inicial, numero_final);
        CREATE INDEX idx_ift_rangos_tipo ON ift_rangos (tipo_servicio);
        CREATE INDEX idx_ift_rangos_operador ON ift_rangos (operador);
        """
        
        result = self.execute_sql(sql, "Creaci√≥n tabla ift_rangos")
        return result is not None
    
    def load_ift_to_db(self):
        """Cargar datos IFT usando COPY"""
        try:
            logger.info("üì• Preparando datos para carga masiva...")
            
            # Crear archivo CSV temporal para COPY
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv', encoding='utf-8') as f:
                temp_file = f.name
                
                # Escribir header
                f.write("numero_inicial,numero_final,cantidad_numeros,tipo_servicio,operador,fecha_asignacion\n")
                
                # Escribir datos
                for _, row in self.df_ift.iterrows():
                    fecha = row['fecha_asignacion'].strftime('%Y-%m-%d') if pd.notna(row['fecha_asignacion']) else '\\N'
                    operador_clean = str(row['operador']).replace(',', ';').replace('\n', ' ')
                    
                    f.write(f"{int(row['numero_inicial'])},{int(row['numero_final'])},{int(row['cantidad_numeros'])},{row['tipo_servicio']},{operador_clean},{fecha}\n")
            
            logger.info(f"üìÑ Archivo temporal creado: {temp_file}")
            
            # Copiar archivo al contenedor
            container_file = '/tmp/ift_data.csv'
            copy_cmd = ['docker', 'cp', temp_file, f'sms_postgres:{container_file}']
            
            copy_result = subprocess.run(copy_cmd, capture_output=True, text=True)
            if copy_result.returncode != 0:
                logger.error(f"‚ùå Error copiando archivo: {copy_result.stderr}")
                return False
            
            logger.info("üìã Archivo copiado al contenedor")
            
            # Ejecutar COPY
            copy_sql = f"""
            COPY ift_rangos (numero_inicial, numero_final, cantidad_numeros, tipo_servicio, operador, fecha_asignacion)
            FROM '{container_file}'
            WITH (FORMAT csv, HEADER true, NULL '\\N');
            """
            
            result = self.execute_sql(copy_sql, "Carga masiva COPY")
            
            # Limpiar archivo temporal
            os.unlink(temp_file)
            
            if result:
                # Verificar carga
                count_result = self.execute_sql("SELECT COUNT(*) FROM ift_rangos;", "Conteo final")
                if count_result:
                    count = count_result.strip().split('\n')[2].strip()
                    logger.info(f"‚úÖ Datos IFT cargados: {count} rangos")
                return True
            else:
                return False
            
        except Exception as e:
            logger.error(f"‚ùå Error en carga masiva: {e}")
            return False
    
    def create_verification_function(self):
        """Crear funci√≥n de verificaci√≥n"""
        logger.info("‚öôÔ∏è Creando funci√≥n de verificaci√≥n...")
        
        sql = """
        CREATE OR REPLACE FUNCTION verificar_numero_ift(numero_telefono BIGINT)
        RETURNS TABLE(
            es_movil BOOLEAN,
            operador TEXT,
            tipo_servicio VARCHAR(10),
            fecha_asignacion DATE,
            encontrado BOOLEAN
        ) AS $$
        BEGIN
            RETURN QUERY
            SELECT 
                CASE WHEN r.tipo_servicio = 'MPP' THEN TRUE ELSE FALSE END as es_movil,
                r.operador,
                r.tipo_servicio,
                r.fecha_asignacion,
                TRUE as encontrado
            FROM ift_rangos r
            WHERE numero_telefono >= r.numero_inicial 
              AND numero_telefono <= r.numero_final
            LIMIT 1;
            
            IF NOT FOUND THEN
                RETURN QUERY SELECT FALSE, 'DESCONOCIDO'::TEXT, 'UNKNOWN'::VARCHAR(10), NULL::DATE, FALSE;
            END IF;
        END;
        $$ LANGUAGE plpgsql;
        """
        
        result = self.execute_sql(sql, "Funci√≥n de verificaci√≥n")
        
        if result:
            # Test de la funci√≥n
            test_result = self.execute_sql(
                "SELECT * FROM verificar_numero_ift(5551234567);",
                "Test funci√≥n verificaci√≥n"
            )
            if test_result:
                logger.info(f"üß™ Test funci√≥n: {test_result.strip()}")
            return True
        
        return False
    
    def run_sample_validation(self, sample_size=10000):
        """Validaci√≥n en muestra"""
        logger.info(f"üîç Ejecutando validaci√≥n en muestra de {sample_size:,} registros...")
        
        sql = f"""
        -- Crear muestra
        CREATE TEMP TABLE temp_sample AS
        SELECT id, phone_national, status, operator
        FROM contacts 
        WHERE phone_national IS NOT NULL 
          AND phone_national ~ '^[0-9]+$'
        ORDER BY RANDOM()
        LIMIT {sample_size};
        
        -- Ejecutar validaci√≥n
        CREATE TEMP TABLE temp_validation_results AS
        SELECT 
            ts.id,
            ts.phone_national,
            ts.status as status_actual,
            ts.operator as operador_actual,
            ift.es_movil,
            ift.operador as operador_ift,
            ift.tipo_servicio,
            ift.encontrado,
            CASE 
                WHEN ift.es_movil = TRUE THEN 'VERIFIED'
                WHEN ift.es_movil = FALSE THEN 'NOT_MOBILE'
                ELSE 'UNKNOWN'
            END as nuevo_status
        FROM temp_sample ts
        CROSS JOIN LATERAL verificar_numero_ift(ts.phone_national::BIGINT) ift;
        
        -- Resultados por status
        SELECT 
            status_actual,
            nuevo_status,
            COUNT(*) as cantidad,
            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as porcentaje
        FROM temp_validation_results
        GROUP BY status_actual, nuevo_status
        ORDER BY cantidad DESC;
        """
        
        result = self.execute_sql(sql, "Validaci√≥n de muestra")
        
        if result:
            logger.info("üìä Resultados de validaci√≥n:")
            logger.info(result)
            
            # Estad√≠sticas de operadores
            op_sql = """
            SELECT 
                operador_ift,
                COUNT(*) as cantidad
            FROM temp_validation_results
            WHERE encontrado = TRUE
            GROUP BY operador_ift
            ORDER BY cantidad DESC
            LIMIT 10;
            """
            
            op_result = self.execute_sql(op_sql, "Top operadores")
            if op_result:
                logger.info("üè¢ Top operadores identificados:")
                logger.info(op_result)
            
            return True
        
        return False
    
    def run_integration(self):
        """Ejecutar integraci√≥n completa"""
        logger.info("üöÄ INICIANDO INTEGRACION IFT")
        logger.info("=" * 60)
        
        steps = [
            ("üîç Test conexi√≥n", self.test_connection),
            ("üìÇ Cargar datos IFT", self.load_ift_data),
            ("üèóÔ∏è Crear tabla IFT", self.create_ift_table),
            ("üì• Cargar IFT a BD", self.load_ift_to_db),
            ("‚öôÔ∏è Crear funci√≥n verificaci√≥n", self.create_verification_function),
            ("üîç Validaci√≥n muestra", lambda: self.run_sample_validation(10000)),
        ]
        
        for step_name, step_func in steps:
            logger.info(f"\n{step_name}...")
            start_time = time.time()
            
            if not step_func():
                logger.error(f"‚ùå Fall√≥: {step_name}")
                return False
            
            elapsed = time.time() - start_time
            logger.info(f"‚úÖ Completado: {step_name} ({elapsed:.1f}s)")
        
        logger.info("\nüéâ INTEGRACION IFT COMPLETADA CON EXITO")
        return True

def main():
    """Funci√≥n principal"""
    integrator = IFTIntegratorDocker()
    
    print("üöÄ INTEGRADOR DE DATOS IFT - VERSION DOCKER")
    print("=" * 60)
    print("Este script integrar√° los datos oficiales del IFT")
    print("usando comandos Docker directos para m√°xima compatibilidad.")
    print()
    
    success = integrator.run_integration()
    
    if success:
        print("\nüéä ¬°INTEGRACION COMPLETADA EXITOSAMENTE!")
        print("üìã Revisa 'ift_integration.log' para detalles completos")
        print("üéØ La base de datos ahora tiene datos oficiales del IFT")
    else:
        print("\n‚ùå La integraci√≥n fall√≥. Revisa los logs.")

if __name__ == "__main__":
    main()