#!/usr/bin/env python3
"""
Optimizador de PostgreSQL para carga masiva
SMS Marketing Platform - DÃA 4
"""

import asyncio
import logging
from typing import Dict, List, Any

import asyncpg

logger = logging.getLogger(__name__)

class PostgreSQLOptimizer:
    """Optimizador de PostgreSQL para migraciÃ³n masiva"""
    
    def __init__(self, postgres_url: str = "postgresql://sms_user:sms_password@localhost:15432/sms_marketing"):
        self.postgres_url = postgres_url
        
    async def optimize_for_bulk_load(self) -> bool:
        """Optimizar PostgreSQL para carga masiva"""
        
        logger.info("âš™ï¸  Optimizando PostgreSQL para carga masiva...")
        
        conn = await asyncpg.connect(self.postgres_url)
        
        try:
            # Configuraciones para carga masiva
            optimizations = [
                # Deshabilitar autocommit para mejor performance
                "SET autocommit = off",
                
                # Aumentar work_mem para operaciones de ordenamiento
                "SET work_mem = '256MB'",
                
                # Aumentar maintenance_work_mem para operaciones de mantenimiento
                "SET maintenance_work_mem = '1GB'",
                
                # Deshabilitar synchronous_commit para mejor performance (menos durabilidad)
                "SET synchronous_commit = off",
                
                # Aumentar checkpoint_segments para reducir checkpoints
                "SET max_wal_size = '2GB'",
                
                # Reducir random_page_cost para SSD
                "SET random_page_cost = 1.1",
                
                # Aumentar effective_cache_size
                "SET effective_cache_size = '4GB'",
                
                # Configurar parallel workers
                "SET max_parallel_workers_per_gather = 4",
                "SET max_parallel_workers = 8",
                
                # Configurar autovacuum para ser menos agresivo durante carga
                "SET autovacuum = off"
            ]
            
            for sql in optimizations:
                try:
                    await conn.execute(sql)
                    logger.info(f"âœ… {sql}")
                except Exception as e:
                    logger.warning(f"âš ï¸  No se pudo aplicar: {sql} - {e}")
            
            # Verificar configuraciones actuales
            await self._show_current_settings(conn)
            
            logger.info("âœ… OptimizaciÃ³n completada")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error optimizando PostgreSQL: {e}")
            return False
            
        finally:
            await conn.close()
    
    async def restore_normal_settings(self) -> bool:
        """Restaurar configuraciones normales post-migraciÃ³n"""
        
        logger.info("ğŸ”„ Restaurando configuraciones normales...")
        
        conn = await asyncpg.connect(self.postgres_url)
        
        try:
            # Restaurar configuraciones normales
            restorations = [
                "SET synchronous_commit = on",
                "SET autovacuum = on",
                "SET work_mem = '4MB'",
                "SET maintenance_work_mem = '64MB'"
            ]
            
            for sql in restorations:
                try:
                    await conn.execute(sql)
                    logger.info(f"âœ… {sql}")
                except Exception as e:
                    logger.warning(f"âš ï¸  No se pudo restaurar: {sql} - {e}")
            
            # Ejecutar VACUUM y ANALYZE despuÃ©s de carga masiva
            logger.info("ğŸ§¹ Ejecutando VACUUM ANALYZE...")
            await conn.execute("VACUUM ANALYZE contacts")
            
            # Actualizar estadÃ­sticas
            logger.info("ğŸ“Š Actualizando estadÃ­sticas...")
            await conn.execute("ANALYZE contacts")
            
            logger.info("âœ… RestauraciÃ³n completada")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error restaurando configuraciones: {e}")
            return False
            
        finally:
            await conn.close()
    
    async def _show_current_settings(self, conn: asyncpg.Connection):
        """Mostrar configuraciones actuales"""
        
        settings = [
            "work_mem",
            "maintenance_work_mem", 
            "synchronous_commit",
            "max_wal_size",
            "effective_cache_size",
            "autovacuum"
        ]
        
        logger.info("ğŸ“Š Configuraciones actuales:")
        
        for setting in settings:
            try:
                result = await conn.fetchrow(f"SHOW {setting}")
                if result:
                    logger.info(f"   {setting}: {result[0]}")
            except:
                pass
    
    async def create_performance_indexes(self) -> bool:
        """Crear Ã­ndices adicionales para performance"""
        
        logger.info("ğŸ” Creando Ã­ndices de performance...")
        
        conn = await asyncpg.connect(self.postgres_url)
        
        try:
            # Ãndices adicionales para consultas frecuentes
            additional_indexes = [
                # Ãndice compuesto para bÃºsquedas por estado y status
                "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_contacts_state_status_mobile ON contacts(state_code, status, is_mobile) WHERE opt_out_at IS NULL",
                
                # Ãndice para bÃºsquedas de texto en nombres
                "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_contacts_name_gin ON contacts USING gin(to_tsvector('spanish', full_name)) WHERE full_name IS NOT NULL",
                
                # Ãndice para rangos de fechas
                "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_contacts_created_range ON contacts(created_at) WHERE created_at >= '2025-01-01'",
                
                # Ãndice para operadores
                "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_contacts_operator_mobile ON contacts(operator, is_mobile) WHERE operator IS NOT NULL",
                
                # Ãndice para conteo rÃ¡pido por LADA
                "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_contacts_lada_status ON contacts(lada, status) WHERE lada IS NOT NULL"
            ]
            
            for sql in additional_indexes:
                try:
                    logger.info(f"ğŸ”¨ Creando Ã­ndice...")
                    await conn.execute(sql)
                    logger.info(f"âœ… Ãndice creado")
                except Exception as e:
                    logger.warning(f"âš ï¸  Error creando Ã­ndice: {e}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error creando Ã­ndices: {e}")
            return False
            
        finally:
            await conn.close()
    
    async def analyze_table_statistics(self) -> Dict[str, Any]:
        """Analizar estadÃ­sticas de tabla despuÃ©s de migraciÃ³n"""
        
        logger.info("ğŸ“Š Analizando estadÃ­sticas de tabla...")
        
        conn = await asyncpg.connect(self.postgres_url)
        
        try:
            # EstadÃ­sticas bÃ¡sicas
            stats_result = await conn.fetchrow("""
                SELECT 
                    schemaname,
                    tablename,
                    attname,
                    n_distinct,
                    correlation
                FROM pg_stats 
                WHERE tablename = 'contacts' 
                AND attname IN ('phone_e164', 'state_code', 'lada', 'status')
                ORDER BY attname
            """)
            
            # TamaÃ±o de tabla
            size_result = await conn.fetchrow("""
                SELECT 
                    pg_size_pretty(pg_total_relation_size('contacts')) as total_size,
                    pg_size_pretty(pg_relation_size('contacts')) as table_size,
                    pg_size_pretty(pg_indexes_size('contacts')) as indexes_size
            """)
            
            # InformaciÃ³n de Ã­ndices
            indexes_result = await conn.fetch("""
                SELECT 
                    indexname,
                    indexdef,
                    pg_size_pretty(pg_relation_size(indexname::regclass)) as size
                FROM pg_indexes 
                WHERE tablename = 'contacts'
                ORDER BY pg_relation_size(indexname::regclass) DESC
            """)
            
            statistics = {
                "table_size": size_result['table_size'] if size_result else "Unknown",
                "total_size": size_result['total_size'] if size_result else "Unknown", 
                "indexes_size": size_result['indexes_size'] if size_result else "Unknown",
                "indexes": [
                    {
                        "name": row['indexname'],
                        "size": row['size'],
                        "definition": row['indexdef'][:100] + "..." if len(row['indexdef']) > 100 else row['indexdef']
                    } 
                    for row in indexes_result
                ]
            }
            
            logger.info(f"ğŸ“Š TamaÃ±o total: {statistics['total_size']}")
            logger.info(f"ğŸ“Š TamaÃ±o tabla: {statistics['table_size']}")
            logger.info(f"ğŸ“Š TamaÃ±o Ã­ndices: {statistics['indexes_size']}")
            logger.info(f"ğŸ“Š NÃºmero de Ã­ndices: {len(statistics['indexes'])}")
            
            return statistics
            
        except Exception as e:
            logger.error(f"âŒ Error analizando estadÃ­sticas: {e}")
            return {}
            
        finally:
            await conn.close()

async def main():
    """FunciÃ³n principal de optimizaciÃ³n"""
    print("âš™ï¸  Optimizador PostgreSQL - SMS Marketing Platform")
    print("="*60)
    
    optimizer = PostgreSQLOptimizer()
    
    # Optimizar para carga masiva
    if await optimizer.optimize_for_bulk_load():
        print("âœ… PostgreSQL optimizado para carga masiva")
    else:
        print("âŒ Error optimizando PostgreSQL")
        return
    
    # Simular migraciÃ³n (en uso real, aquÃ­ irÃ­a la migraciÃ³n)
    print("\nâ³ Simulando migraciÃ³n...")
    await asyncio.sleep(2)
    
    # Restaurar configuraciones normales
    if await optimizer.restore_normal_settings():
        print("âœ… Configuraciones restauradas")
    
    # Crear Ã­ndices de performance
    if await optimizer.create_performance_indexes():
        print("âœ… Ãndices de performance creados")
    
    # Analizar estadÃ­sticas
    stats = await optimizer.analyze_table_statistics()
    if stats:
        print("âœ… AnÃ¡lisis de estadÃ­sticas completado")

if __name__ == "__main__":
    asyncio.run(main())