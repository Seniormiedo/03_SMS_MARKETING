#!/usr/bin/env python3
"""
SOLUCI√ìN DEFINITIVA DE MIGRACI√ìN
Usa conexi√≥n directa a PostgreSQL con asyncpg para evitar l√≠mites de Windows completamente
"""

import asyncio
import sqlite3
import sys
import os
import time
import json
import psutil
from datetime import datetime, timedelta
from pathlib import Path

# Agregar el directorio ra√≠z al path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.migration_manager import DataTransformer

class UltimateMigrationSolution:
    """Soluci√≥n definitiva usando conexi√≥n directa asyncpg"""
    
    def __init__(self):
        self.start_time = None
        self.total_records = 0
        self.processed_records = 0
        self.successful_inserts = 0
        self.failed_inserts = 0
        self.batch_size = 10000  # 10K registros por lote
        self.insert_batch_size = 100  # 100 registros por transacci√≥n
        
    def log_message(self, message, level="INFO"):
        """Log con timestamp"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {level}: {message}")
        
    def check_system_resources(self):
        """Verificar recursos del sistema"""
        self.log_message("üîç Verificando recursos del sistema...")
        
        memory = psutil.virtual_memory()
        memory_gb = memory.total / (1024**3)
        memory_available_gb = memory.available / (1024**3)
        
        disk = psutil.disk_usage('.')
        disk_free_gb = disk.free / (1024**3)
        
        self.log_message(f"üíæ Memoria: {memory_available_gb:.1f}GB disponible de {memory_gb:.1f}GB total")
        self.log_message(f"üíΩ Disco: {disk_free_gb:.1f}GB libres")
        
        return disk_free_gb >= 40
    
    def backup_source_database(self):
        """Crear backup de numeros.db"""
        self.log_message("üíæ Creando backup de numeros.db...")
        
        source_path = Path("numeros.db")
        if not source_path.exists():
            self.log_message("‚ùå ERROR: numeros.db no encontrado", "ERROR")
            return False
        
        backup_name = f"numeros_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
        backup_path = Path("backups") / backup_name
        backup_path.parent.mkdir(exist_ok=True)
        
        try:
            import shutil
            shutil.copy2(source_path, backup_path)
            backup_size = backup_path.stat().st_size
            self.log_message(f"‚úÖ Backup creado: {backup_path} ({backup_size/1024**3:.1f}GB)")
            return True
        except Exception as e:
            self.log_message(f"‚ùå ERROR creando backup: {e}", "ERROR")
            return False
    
    def get_total_records(self):
        """Obtener conteo exacto de registros"""
        self.log_message("üìä Contando registros totales en numeros.db...")
        
        try:
            conn = sqlite3.connect("numeros.db")
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM numeros")
            count = cursor.fetchone()[0]
            conn.close()
            
            self.total_records = count
            total_batches = (count + self.batch_size - 1) // self.batch_size
            
            self.log_message(f"üì± Total de registros: {count:,}")
            self.log_message(f"üì¶ Total de lotes: {total_batches:,} (tama√±o: {self.batch_size:,})")
            
            return count
        except Exception as e:
            self.log_message(f"‚ùå ERROR contando registros: {e}", "ERROR")
            return 0
    
    async def get_postgres_connection(self):
        """Obtener conexi√≥n directa a PostgreSQL usando asyncpg"""
        try:
            import asyncpg
            
            # Configuraci√≥n de conexi√≥n
            connection = await asyncpg.connect(
                host='localhost',
                port=15432,  # Puerto mapeado de Docker
                user='sms_user',
                password='sms_password',
                database='sms_marketing'
            )
            
            self.log_message("‚úÖ Conexi√≥n directa a PostgreSQL establecida")
            return connection
            
        except ImportError:
            self.log_message("‚ùå ERROR: asyncpg no est√° instalado. Instalando...", "ERROR")
            import subprocess
            subprocess.run([sys.executable, '-m', 'pip', 'install', 'asyncpg'], check=True)
            
            import asyncpg
            connection = await asyncpg.connect(
                host='localhost',
                port=15432,
                user='sms_user',
                password='sms_password',
                database='sms_marketing'
            )
            
            self.log_message("‚úÖ Conexi√≥n directa a PostgreSQL establecida (asyncpg instalado)")
            return connection
            
        except Exception as e:
            self.log_message(f"‚ùå ERROR conectando a PostgreSQL: {e}", "ERROR")
            return None
    
    async def clear_target_table(self, connection):
        """Limpiar tabla de destino"""
        self.log_message("üßπ Limpiando tabla contacts...")
        
        try:
            await connection.execute("TRUNCATE TABLE messages, contacts RESTART IDENTITY CASCADE;")
            self.log_message("‚úÖ Tabla contacts limpiada")
            return True
        except Exception as e:
            self.log_message(f"‚ùå Error limpiando tabla: {e}", "ERROR")
            return False
    
    async def optimize_postgresql(self, connection):
        """Optimizar PostgreSQL para inserci√≥n masiva"""
        self.log_message("‚ö° Optimizando PostgreSQL...")
        
        optimization_queries = [
            "SET synchronous_commit = off;",
            "SET wal_buffers = '64MB';",
            "SET checkpoint_completion_target = 0.9;",
            "SET maintenance_work_mem = '1GB';",
            "SET work_mem = '256MB';"
        ]
        
        for query in optimization_queries:
            try:
                await connection.execute(query)
            except Exception as e:
                self.log_message(f"‚ö†Ô∏è  Error en optimizaci√≥n: {e}", "WARNING")
        
        self.log_message("‚úÖ Optimizaci√≥n PostgreSQL completada")
    
    async def migrate_batch_direct(self, connection, batch_number, offset, limit):
        """Migrar un lote usando conexi√≥n directa asyncpg"""
        batch_start = time.time()
        total_batches = (self.total_records + self.batch_size - 1) // self.batch_size
        self.log_message(f"üîÑ Procesando lote {batch_number}/{total_batches} (registros {offset+1:,} - {offset+limit:,})")
        
        try:
            # Obtener datos de SQLite
            sqlite_conn = sqlite3.connect("numeros.db")
            sqlite_conn.row_factory = sqlite3.Row
            cursor = sqlite_conn.cursor()
            
            cursor.execute(f"SELECT * FROM numeros LIMIT {limit} OFFSET {offset}")
            batch_records = [dict(row) for row in cursor.fetchall()]
            sqlite_conn.close()
            
            if not batch_records:
                return 0
            
            # Transformar registros
            transformer = DataTransformer()
            transformed_records = []
            
            for record in batch_records:
                result = transformer.transform_record(record)
                if result["success"]:
                    transformed_records.append(result["data"])
            
            if not transformed_records:
                return 0
            
            # Insertar usando transacciones por lotes
            inserted_count = 0
            
            # Preparar consulta INSERT
            insert_query = """
            INSERT INTO contacts (
                phone_e164, phone_national, phone_original, full_name, address, neighborhood,
                lada, state_code, state_name, municipality, city, is_mobile, operator,
                status, status_updated_at, status_source, send_count, last_sent_at,
                opt_out_at, opt_out_method, last_validated_at, validation_attempts,
                source, import_batch_id
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23, $24)
            ON CONFLICT (phone_e164) DO NOTHING
            """
            
            # Insertar en sub-lotes usando transacciones
            for i in range(0, len(transformed_records), self.insert_batch_size):
                sub_batch = transformed_records[i:i+self.insert_batch_size]
                
                try:
                    async with connection.transaction():
                        for data in sub_batch:
                            await connection.execute(
                                insert_query,
                                data.get("phone_e164"),
                                data.get("phone_national"),
                                data.get("phone_original"),
                                data.get("full_name"),
                                data.get("address"),
                                data.get("neighborhood"),
                                data.get("lada"),
                                data.get("state_code"),
                                data.get("state_name"),
                                data.get("municipality"),
                                data.get("city"),
                                data.get("is_mobile"),
                                data.get("operator"),
                                data.get("status", "UNKNOWN"),
                                None,  # status_updated_at
                                None,  # status_source
                                0,     # send_count
                                None,  # last_sent_at
                                None,  # opt_out_at
                                None,  # opt_out_method
                                None,  # last_validated_at
                                0,     # validation_attempts
                                data.get("source", "TELCEL2022"),
                                None   # import_batch_id
                            )
                        
                        inserted_count += len(sub_batch)
                        
                except Exception as e:
                    self.log_message(f"‚ö†Ô∏è  Error en sub-lote: {e}", "WARNING")
            
            # Estad√≠sticas del lote
            batch_time = time.time() - batch_start
            records_per_second = len(batch_records) / batch_time if batch_time > 0 else 0
            
            self.processed_records += len(batch_records)
            self.successful_inserts += inserted_count
            self.failed_inserts += (len(batch_records) - inserted_count)
            
            progress_percent = (self.processed_records / self.total_records) * 100
            
            self.log_message(f"‚úÖ Lote {batch_number} completado:")
            self.log_message(f"   üìä Procesados: {len(batch_records):,} | Insertados: {inserted_count:,}")
            self.log_message(f"   ‚è±Ô∏è  Tiempo: {batch_time:.1f}s | Velocidad: {records_per_second:.0f} reg/s")
            self.log_message(f"   üìà Progreso total: {progress_percent:.1f}% ({self.processed_records:,}/{self.total_records:,})")
            
            return inserted_count
            
        except Exception as e:
            self.log_message(f"‚ùå ERROR en lote {batch_number}: {e}", "ERROR")
            return 0
    
    def estimate_completion_time(self):
        """Estimar tiempo restante"""
        if self.processed_records == 0:
            return "Calculando..."
        
        elapsed_time = time.time() - self.start_time
        records_per_second = self.processed_records / elapsed_time
        remaining_records = self.total_records - self.processed_records
        
        if records_per_second > 0:
            remaining_seconds = remaining_records / records_per_second
            completion_time = datetime.now() + timedelta(seconds=remaining_seconds)
            return completion_time.strftime("%Y-%m-%d %H:%M:%S")
        else:
            return "No disponible"
    
    async def validate_migration(self, connection):
        """Validar migraci√≥n completa"""
        self.log_message("üîç Validando migraci√≥n completa...")
        
        validation_queries = [
            ("Total registros", "SELECT COUNT(*) FROM contacts"),
            ("N√∫meros E.164 v√°lidos", "SELECT COUNT(*) FROM contacts WHERE phone_e164 ~ '^\\+52[0-9]{10}$'"),
            ("Estados √∫nicos", "SELECT COUNT(DISTINCT state_code) FROM contacts WHERE state_code IS NOT NULL"),
            ("Registros m√≥viles", "SELECT COUNT(*) FROM contacts WHERE is_mobile = true")
        ]
        
        validation_results = {}
        
        for description, query in validation_queries:
            try:
                result = await connection.fetchval(query)
                validation_results[description] = result
                self.log_message(f"   ‚úÖ {description}: {result:,}")
            except Exception as e:
                self.log_message(f"   ‚ùå Excepci√≥n en {description}: {e}", "ERROR")
                validation_results[description] = 0
        
        return validation_results
    
    async def restore_postgresql_config(self, connection):
        """Restaurar configuraci√≥n normal de PostgreSQL"""
        self.log_message("üîß Restaurando configuraci√≥n PostgreSQL...")
        
        restore_queries = [
            "RESET synchronous_commit;",
            "RESET wal_buffers;",
            "RESET checkpoint_completion_target;",
            "RESET maintenance_work_mem;",
            "RESET work_mem;",
            "VACUUM ANALYZE contacts;"
        ]
        
        for query in restore_queries:
            try:
                await connection.execute(query)
            except Exception as e:
                self.log_message(f"‚ö†Ô∏è  Error en restauraci√≥n: {e}", "WARNING")
        
        self.log_message("‚úÖ Configuraci√≥n PostgreSQL restaurada")
    
    async def execute_ultimate_migration(self):
        """Ejecutar migraci√≥n completa usando conexi√≥n directa"""
        self.start_time = time.time()
        
        self.log_message("üöÄ INICIANDO MIGRACI√ìN DEFINITIVA DE 36.6 MILLONES DE REGISTROS")
        self.log_message("=" * 80)
        
        # FASE 1: Preparaci√≥n
        self.log_message("üìã FASE 1: PREPARACI√ìN")
        if not self.check_system_resources():
            return False
        
        if not self.backup_source_database():
            return False
        
        if self.get_total_records() == 0:
            return False
        
        # Obtener conexi√≥n directa
        connection = await self.get_postgres_connection()
        if not connection:
            return False
        
        try:
            await self.optimize_postgresql(connection)
            
            if not await self.clear_target_table(connection):
                return False
            
            # FASE 2: Migraci√≥n usando conexi√≥n directa
            self.log_message("\nüì¶ FASE 2: MIGRACI√ìN USANDO CONEXI√ìN DIRECTA ASYNCPG")
            
            total_batches = (self.total_records + self.batch_size - 1) // self.batch_size
            self.log_message(f"Procesando {total_batches:,} lotes de {self.batch_size:,} registros cada uno")
            
            for batch_num in range(1, total_batches + 1):
                offset = (batch_num - 1) * self.batch_size
                limit = min(self.batch_size, self.total_records - offset)
                
                if limit <= 0:
                    break
                
                # Migrar lote usando conexi√≥n directa
                inserted = await self.migrate_batch_direct(connection, batch_num, offset, limit)
                
                # Mostrar progreso cada 10 lotes
                if batch_num % 10 == 0:
                    eta = self.estimate_completion_time()
                    self.log_message(f"üìä PROGRESO: {batch_num}/{total_batches} lotes | ETA: {eta}")
                    
                    memory = psutil.virtual_memory()
                    self.log_message(f"üíæ Memoria: {memory.percent}% usado")
            
            # FASE 3: Validaci√≥n final
            self.log_message("\nüîç FASE 3: VALIDACI√ìN FINAL")
            validation_results = await self.validate_migration(connection)
            
            # FASE 4: Optimizaci√≥n post-migraci√≥n
            self.log_message("\n‚ö° FASE 4: OPTIMIZACI√ìN POST-MIGRACI√ìN")
            await self.restore_postgresql_config(connection)
            
        finally:
            # Cerrar conexi√≥n
            await connection.close()
            self.log_message("üîå Conexi√≥n PostgreSQL cerrada")
        
        # Estad√≠sticas finales
        total_time = time.time() - self.start_time
        records_per_second = self.processed_records / total_time if total_time > 0 else 0
        
        self.log_message("\n" + "=" * 80)
        self.log_message("üéØ MIGRACI√ìN DEFINITIVA COMPLETADA")
        self.log_message("=" * 80)
        self.log_message(f"üì± Registros procesados: {self.processed_records:,}")
        self.log_message(f"‚úÖ Inserciones exitosas: {self.successful_inserts:,}")
        self.log_message(f"‚ùå Inserciones fallidas: {self.failed_inserts:,}")
        self.log_message(f"‚è±Ô∏è  Tiempo total: {total_time/3600:.1f} horas")
        self.log_message(f"üöÄ Velocidad promedio: {records_per_second:.0f} registros/segundo")
        self.log_message(f"üéØ Tasa de √©xito: {(self.successful_inserts/self.processed_records*100):.1f}%")
        
        # Guardar reporte final
        self.save_final_report(validation_results, total_time)
        
        return True
    
    def save_final_report(self, validation_results, total_time):
        """Guardar reporte final de migraci√≥n"""
        report = {
            "migration_summary": {
                "total_records": self.total_records,
                "processed_records": self.processed_records,
                "successful_inserts": self.successful_inserts,
                "failed_inserts": self.failed_inserts,
                "success_rate": (self.successful_inserts/self.processed_records*100) if self.processed_records > 0 else 0,
                "total_time_hours": total_time/3600,
                "records_per_second": self.processed_records/total_time if total_time > 0 else 0
            },
            "validation_results": validation_results,
            "timestamp": datetime.now().isoformat()
        }
        
        report_path = f"MIGRACION_DEFINITIVA_36M_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            self.log_message(f"üìÑ Reporte guardado: {report_path}")
        except Exception as e:
            self.log_message(f"‚ö†Ô∏è  Error guardando reporte: {e}", "WARNING")

async def main():
    """Funci√≥n principal"""
    solution = UltimateMigrationSolution()
    
    print("üî• MIGRACI√ìN DEFINITIVA DE 36.6 MILLONES DE REGISTROS")
    print("üöÄ CONEXI√ìN DIRECTA ASYNCPG - SIN L√çMITES DE WINDOWS")
    print("‚ö†Ô∏è  ADVERTENCIA: Esta operaci√≥n puede tomar 4-8 horas")
    print("üìã Caracter√≠sticas de esta soluci√≥n:")
    print("   - Conexi√≥n directa a PostgreSQL con asyncpg")
    print("   - Sin l√≠mites de l√≠nea de comandos de Windows")
    print("   - Transacciones por lotes de 100 registros")
    print("   - Lotes principales de 10K registros")
    print("   - Rendimiento optimizado")
    
    confirm = input("\n¬øContinuar con la migraci√≥n definitiva? (yes/no): ").lower().strip()
    
    if confirm == 'yes':
        success = await solution.execute_ultimate_migration()
        
        if success:
            print("\nüéâ ¬°MIGRACI√ìN DEFINITIVA COMPLETADA EXITOSAMENTE!")
            print("üìä Revisa el reporte JSON generado para detalles completos")
        else:
            print("\n‚ùå MIGRACI√ìN FALL√ì - Revisa los logs para detalles")
    else:
        print("\n‚ùå Migraci√≥n cancelada por el usuario")

if __name__ == "__main__":
    asyncio.run(main())