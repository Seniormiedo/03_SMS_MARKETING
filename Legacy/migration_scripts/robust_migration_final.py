#!/usr/bin/env python3
"""
MIGRACI√ìN ROBUSTA FINAL - ENFOQUE H√çBRIDO
Combina velocidad con estabilidad, evitando problemas de SQLite
"""

import sqlite3
import subprocess
import sys
import os
import time
import json
import psutil
import tempfile
from datetime import datetime, timedelta
from pathlib import Path

# Agregar el directorio ra√≠z al path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.migration_manager import DataTransformer

class RobustMigrationFinal:
    """Migraci√≥n robusta usando m√∫ltiples conexiones SQLite y transacciones peque√±as"""
    
    def __init__(self):
        self.start_time = None
        self.total_records = 0
        self.processed_records = 0
        self.successful_inserts = 0
        self.failed_inserts = 0
        self.batch_size = 10000  # Lotes m√°s peque√±os para estabilidad
        self.transaction_size = 1000  # Transacciones peque√±as
        
    def log_message(self, message, level="INFO"):
        """Log con timestamp"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {level}: {message}")
        
    def get_total_records(self):
        """Obtener conteo exacto de registros"""
        self.log_message("üìä Contando registros totales...")
        
        try:
            conn = sqlite3.connect("numeros.db")
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM numeros")
            count = cursor.fetchone()[0]
            conn.close()
            
            self.total_records = count
            total_batches = (count + self.batch_size - 1) // self.batch_size
            
            self.log_message(f"üì± Total de registros: {count:,}")
            self.log_message(f"üì¶ Total de lotes: {total_batches:,} (tama√±o: {self.batch_size:,})")
            
            return count
        except Exception as e:
            self.log_message(f"‚ùå ERROR contando registros: {e}", "ERROR")
            return 0
    
    def optimize_postgresql_moderate(self):
        """Optimizaci√≥n moderada de PostgreSQL"""
        self.log_message("‚ö° Aplicando optimizaci√≥n moderada...")
        
        optimization_commands = [
            "ALTER SYSTEM SET synchronous_commit = off;",
            "ALTER SYSTEM SET wal_buffers = '32MB';",
            "ALTER SYSTEM SET checkpoint_completion_target = 0.8;",
            "ALTER SYSTEM SET work_mem = '256MB';",
            "ALTER SYSTEM SET maintenance_work_mem = '1GB';",
            "SELECT pg_reload_conf();"
        ]
        
        for cmd in optimization_commands:
            try:
                subprocess.run([
                    'docker-compose', 'exec', '-T', 'postgres',
                    'psql', '-U', 'sms_user', '-d', 'sms_marketing',
                    '-c', cmd
                ], capture_output=True, text=True, timeout=10)
            except:
                pass
        
        self.log_message("‚úÖ Optimizaci√≥n aplicada")
    
    def clear_target_table(self):
        """Limpiar tabla de destino"""
        self.log_message("üßπ Limpiando tabla contacts...")
        
        try:
            result = subprocess.run([
                'docker-compose', 'exec', '-T', 'postgres',
                'psql', '-U', 'sms_user', '-d', 'sms_marketing',
                '-c', 'TRUNCATE TABLE contacts RESTART IDENTITY CASCADE;'
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                self.log_message("‚úÖ Tabla contacts limpiada")
                return True
            else:
                self.log_message(f"‚ùå Error limpiando tabla: {result.stderr}", "ERROR")
                return False
        except Exception as e:
            self.log_message(f"‚ùå Error limpiando tabla: {e}", "ERROR")
            return False
    
    def migrate_batch_robust(self, batch_number, offset, limit):
        """Migrar un lote usando transacciones peque√±as y m√∫ltiples conexiones"""
        batch_start = time.time()
        total_batches = (self.total_records + self.batch_size - 1) // self.batch_size
        self.log_message(f"üîÑ Lote {batch_number}/{total_batches} (registros {offset+1:,} - {offset+limit:,})")
        
        try:
            # Usar nueva conexi√≥n SQLite para cada lote (evita bloqueos)
            conn = sqlite3.connect("numeros.db", timeout=30.0)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # Leer con timeout y reintentos
            max_retries = 3
            for retry in range(max_retries):
                try:
                    cursor.execute(f"SELECT * FROM numeros LIMIT {limit} OFFSET {offset}")
                    batch_records = [dict(row) for row in cursor.fetchall()]
                    break
                except sqlite3.OperationalError as e:
                    if retry < max_retries - 1:
                        self.log_message(f"‚ö†Ô∏è  Reintento {retry + 1} para lote {batch_number}: {e}", "WARNING")
                        time.sleep(1)
                        continue
                    else:
                        raise e
            
            conn.close()
            
            if not batch_records:
                return 0
            
            # Transformar registros
            transformer = DataTransformer()
            transformed_records = []
            
            for record in batch_records:
                result = transformer.transform_record(record)
                if result["success"]:
                    transformed_records.append(result["data"])
            
            if not transformed_records:
                return 0
            
            # Insertar en mini-transacciones
            inserted_count = 0
            
            for i in range(0, len(transformed_records), self.transaction_size):
                mini_batch = transformed_records[i:i+self.transaction_size]
                
                # Crear SQL para mini-transacci√≥n
                values_list = []
                for data in mini_batch:
                    def escape_sql(value):
                        if value is None or value == "":
                            return "NULL"
                        elif isinstance(value, str):
                            escaped = value.replace("'", "''").replace("\\", "\\\\")
                            return f"'{escaped}'"
                        elif isinstance(value, bool):
                            return "TRUE" if value else "FALSE"
                        else:
                            return str(value)
                    
                    values_row = f"({escape_sql(data.get('phone_e164'))}, {escape_sql(data.get('phone_national'))}, {escape_sql(data.get('phone_original'))}, {escape_sql(data.get('full_name'))}, {escape_sql(data.get('address'))}, {escape_sql(data.get('neighborhood'))}, {escape_sql(data.get('lada'))}, {escape_sql(data.get('state_code'))}, {escape_sql(data.get('state_name'))}, {escape_sql(data.get('municipality'))}, {escape_sql(data.get('city'))}, {escape_sql(data.get('is_mobile'))}, {escape_sql(data.get('operator'))}, {escape_sql(data.get('status', 'UNKNOWN'))}, NULL, NULL, 0, NULL, NULL, NULL, NULL, 0, {escape_sql(data.get('source', 'TELCEL2022'))}, NULL)"
                    
                    values_list.append(values_row)
                
                # Crear mini-transacci√≥n SQL
                mini_sql = f"""
BEGIN;
INSERT INTO contacts (
    phone_e164, phone_national, phone_original, full_name, address, neighborhood,
    lada, state_code, state_name, municipality, city, is_mobile, operator,
    status, status_updated_at, status_source, send_count, last_sent_at,
    opt_out_at, opt_out_method, last_validated_at, validation_attempts,
    source, import_batch_id
) VALUES {', '.join(values_list)}
ON CONFLICT (phone_e164) DO NOTHING;
COMMIT;
"""
                
                # Crear archivo temporal para mini-transacci√≥n
                with tempfile.NamedTemporaryFile(mode='w', suffix='.sql', delete=False, encoding='utf-8') as temp_file:
                    temp_file.write(mini_sql)
                    temp_file_path = temp_file.name
                
                try:
                    # Copiar y ejecutar mini-transacci√≥n
                    copy_result = subprocess.run([
                        'docker', 'cp', temp_file_path, f'sms_postgres:/tmp/mini_batch_{i}.sql'
                    ], capture_output=True, text=True, timeout=10)
                    
                    if copy_result.returncode == 0:
                        exec_result = subprocess.run([
                            'docker-compose', 'exec', '-T', 'postgres',
                            'psql', '-U', 'sms_user', '-d', 'sms_marketing',
                            '-f', f'/tmp/mini_batch_{i}.sql'
                        ], capture_output=True, text=True, timeout=30)
                        
                        if exec_result.returncode == 0:
                            inserted_count += len(mini_batch)
                        else:
                            self.log_message(f"‚ö†Ô∏è  Error en mini-transacci√≥n {i}: {exec_result.stderr[:100]}", "WARNING")
                        
                        # Limpiar archivo del contenedor
                        subprocess.run([
                            'docker-compose', 'exec', '-T', 'postgres',
                            'rm', '-f', f'/tmp/mini_batch_{i}.sql'
                        ], capture_output=True)
                    
                finally:
                    # Limpiar archivo local
                    try:
                        os.unlink(temp_file_path)
                    except:
                        pass
            
            # Estad√≠sticas
            batch_time = time.time() - batch_start
            records_per_second = len(batch_records) / batch_time if batch_time > 0 else 0
            
            self.processed_records += len(batch_records)
            self.successful_inserts += inserted_count
            self.failed_inserts += (len(batch_records) - inserted_count)
            
            progress_percent = (self.processed_records / self.total_records) * 100
            
            self.log_message(f"‚úÖ Lote {batch_number} completado:")
            self.log_message(f"   üìä Procesados: {len(batch_records):,} | Insertados: {inserted_count:,}")
            self.log_message(f"   ‚ö° Tiempo: {batch_time:.1f}s | Velocidad: {records_per_second:.0f} reg/s")
            self.log_message(f"   üìà Progreso: {progress_percent:.2f}% ({self.processed_records:,}/{self.total_records:,})")
            
            return inserted_count
            
        except Exception as e:
            self.log_message(f"‚ùå ERROR en lote {batch_number}: {e}", "ERROR")
            return 0
    
    def estimate_completion_time(self):
        """Estimar tiempo restante"""
        if self.processed_records == 0:
            return "Calculando..."
        
        elapsed_time = time.time() - self.start_time
        records_per_second = self.processed_records / elapsed_time
        remaining_records = self.total_records - self.processed_records
        
        if records_per_second > 0:
            remaining_seconds = remaining_records / records_per_second
            completion_time = datetime.now() + timedelta(seconds=remaining_seconds)
            return completion_time.strftime("%Y-%m-%d %H:%M:%S")
        else:
            return "No disponible"
    
    def validate_migration(self):
        """Validar migraci√≥n completa"""
        self.log_message("üîç Validando migraci√≥n completa...")
        
        validation_queries = [
            ("Total registros", "SELECT COUNT(*) FROM contacts"),
            ("N√∫meros E.164 v√°lidos", "SELECT COUNT(*) FROM contacts WHERE phone_e164 ~ '^\\+52[0-9]{10}$'"),
            ("Estados √∫nicos", "SELECT COUNT(DISTINCT state_code) FROM contacts WHERE state_code IS NOT NULL"),
            ("Registros m√≥viles", "SELECT COUNT(*) FROM contacts WHERE is_mobile = true")
        ]
        
        validation_results = {}
        
        for description, query in validation_queries:
            try:
                result = subprocess.run([
                    'docker-compose', 'exec', '-T', 'postgres',
                    'psql', '-U', 'sms_user', '-d', 'sms_marketing',
                    '-t', '-c', query
                ], capture_output=True, text=True, timeout=30)
                
                if result.returncode == 0:
                    count = int(result.stdout.strip())
                    validation_results[description] = count
                    self.log_message(f"   ‚úÖ {description}: {count:,}")
                else:
                    validation_results[description] = 0
            except Exception as e:
                validation_results[description] = 0
        
        return validation_results
    
    def restore_postgresql_config(self):
        """Restaurar configuraci√≥n normal de PostgreSQL"""
        self.log_message("üîß Restaurando configuraci√≥n PostgreSQL...")
        
        restore_queries = [
            "ALTER SYSTEM RESET synchronous_commit;",
            "ALTER SYSTEM RESET wal_buffers;",
            "ALTER SYSTEM RESET checkpoint_completion_target;",
            "SELECT pg_reload_conf();",
            "VACUUM ANALYZE contacts;"
        ]
        
        for query in restore_queries:
            try:
                subprocess.run([
                    'docker-compose', 'exec', '-T', 'postgres',
                    'psql', '-U', 'sms_user', '-d', 'sms_marketing',
                    '-c', query
                ], capture_output=True, text=True, timeout=300)
            except:
                pass
        
        self.log_message("‚úÖ Configuraci√≥n PostgreSQL restaurada")
    
    def execute_robust_migration(self):
        """Ejecutar migraci√≥n robusta completa"""
        self.start_time = time.time()
        
        self.log_message("üöÄ INICIANDO MIGRACI√ìN ROBUSTA DE 36.6 MILLONES DE REGISTROS")
        self.log_message("=" * 80)
        
        # FASE 1: Preparaci√≥n
        self.log_message("üìã FASE 1: PREPARACI√ìN")
        
        if self.get_total_records() == 0:
            return False
        
        self.optimize_postgresql_moderate()
        
        if not self.clear_target_table():
            return False
        
        # FASE 2: Migraci√≥n robusta por lotes
        self.log_message("\nüì¶ FASE 2: MIGRACI√ìN ROBUSTA POR LOTES")
        self.log_message("üõ°Ô∏è  Caracter√≠sticas:")
        self.log_message("   - Lotes peque√±os de 10K registros")
        self.log_message("   - Mini-transacciones de 1K registros")
        self.log_message("   - M√∫ltiples conexiones SQLite")
        self.log_message("   - Reintentos autom√°ticos")
        self.log_message("   - Progreso persistente")
        
        total_batches = (self.total_records + self.batch_size - 1) // self.batch_size
        
        for batch_num in range(1, total_batches + 1):
            offset = (batch_num - 1) * self.batch_size
            limit = min(self.batch_size, self.total_records - offset)
            
            if limit <= 0:
                break
            
            # Migrar lote robusto
            inserted = self.migrate_batch_robust(batch_num, offset, limit)
            
            # Mostrar progreso cada 10 lotes
            if batch_num % 10 == 0:
                eta = self.estimate_completion_time()
                self.log_message(f"üìä PROGRESO: {batch_num}/{total_batches} lotes | ETA: {eta}")
                
                memory = psutil.virtual_memory()
                self.log_message(f"üíæ Memoria: {memory.percent}% usado")
                
                # Mostrar progreso intermedio
                current_count = self.get_current_count()
                self.log_message(f"üì± Registros confirmados en BD: {current_count:,}")
        
        # FASE 3: Validaci√≥n final
        self.log_message("\nüîç FASE 3: VALIDACI√ìN FINAL")
        validation_results = self.validate_migration()
        
        # FASE 4: Optimizaci√≥n post-migraci√≥n
        self.log_message("\n‚ö° FASE 4: OPTIMIZACI√ìN POST-MIGRACI√ìN")
        self.restore_postgresql_config()
        
        # Estad√≠sticas finales
        total_time = time.time() - self.start_time
        records_per_second = self.processed_records / total_time if total_time > 0 else 0
        
        self.log_message("\n" + "=" * 80)
        self.log_message("üéØ MIGRACI√ìN ROBUSTA COMPLETADA")
        self.log_message("=" * 80)
        self.log_message(f"üì± Registros procesados: {self.processed_records:,}")
        self.log_message(f"‚úÖ Inserciones exitosas: {self.successful_inserts:,}")
        self.log_message(f"‚ùå Inserciones fallidas: {self.failed_inserts:,}")
        self.log_message(f"‚è±Ô∏è  Tiempo total: {total_time/60:.1f} minutos")
        self.log_message(f"üöÄ Velocidad promedio: {records_per_second:.0f} registros/segundo")
        
        if self.processed_records > 0:
            self.log_message(f"üéØ Tasa de √©xito: {(self.successful_inserts/self.processed_records*100):.1f}%")
        
        # Guardar reporte final
        self.save_final_report(validation_results, total_time)
        
        return True
    
    def get_current_count(self):
        """Obtener conteo actual de registros en PostgreSQL"""
        try:
            result = subprocess.run([
                'docker-compose', 'exec', '-T', 'postgres',
                'psql', '-U', 'sms_user', '-d', 'sms_marketing',
                '-t', '-c', 'SELECT COUNT(*) FROM contacts;'
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                return int(result.stdout.strip())
            else:
                return 0
        except:
            return 0
    
    def save_final_report(self, validation_results, total_time):
        """Guardar reporte final de migraci√≥n"""
        report = {
            "migration_summary": {
                "total_records": self.total_records,
                "processed_records": self.processed_records,
                "successful_inserts": self.successful_inserts,
                "failed_inserts": self.failed_inserts,
                "success_rate": (self.successful_inserts/self.processed_records*100) if self.processed_records > 0 else 0,
                "total_time_minutes": total_time/60,
                "records_per_second": self.processed_records/total_time if total_time > 0 else 0
            },
            "validation_results": validation_results,
            "timestamp": datetime.now().isoformat()
        }
        
        report_path = f"MIGRACION_ROBUSTA_36M_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            self.log_message(f"üìÑ Reporte guardado: {report_path}")
        except Exception as e:
            self.log_message(f"‚ö†Ô∏è  Error guardando reporte: {e}", "WARNING")

def main():
    """Funci√≥n principal"""
    solution = RobustMigrationFinal()
    
    print("üî• MIGRACI√ìN ROBUSTA DE 36.6 MILLONES DE REGISTROS")
    print("üõ°Ô∏è  ENFOQUE H√çBRIDO - VELOCIDAD + ESTABILIDAD")
    print("‚è±Ô∏è  TIEMPO ESTIMADO: 2-4 horas")
    print("üìã Caracter√≠sticas:")
    print("   - Lotes peque√±os de 10K registros (estabilidad)")
    print("   - Mini-transacciones de 1K registros (recuperaci√≥n)")
    print("   - M√∫ltiples conexiones SQLite (evita bloqueos)")
    print("   - Reintentos autom√°ticos (tolerancia a fallos)")
    print("   - Progreso persistente (no se pierde trabajo)")
    print("   - Velocidad estimada: 3,000-5,000 registros/segundo")
    
    confirm = input("\n¬øContinuar con la migraci√≥n robusta? (yes/no): ").lower().strip()
    
    if confirm == 'yes':
        success = solution.execute_robust_migration()
        
        if success:
            print("\nüéâ ¬°MIGRACI√ìN ROBUSTA COMPLETADA EXITOSAMENTE!")
            print("üìä Revisa el reporte JSON generado para detalles completos")
        else:
            print("\n‚ùå MIGRACI√ìN FALL√ì - Revisa los logs para detalles")
    else:
        print("\n‚ùå Migraci√≥n cancelada por el usuario")

if __name__ == "__main__":
    main()